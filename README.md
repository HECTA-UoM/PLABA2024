# PLABA2024 from Manchester (United) NLP
PLABA 2024 system report with shared fined models RoBERTa-Base and prompts for LLMs


# Please cite our work if you use the materiels shared here, the fine-tuning scirpt, prompts, saved models, etc.

@misc{ling2024beemancplabatracktac2024,
      title={BeeManc at the PLABA Track of TAC-2024: RoBERTa for task 1 and LLaMA3.1 and GPT-4o for task 2}, 
      author={Zhidong Ling and Zihao Li and Pablo Romeo and Lifeng Han and Goran Nenadic},
      year={2024},
      eprint={2411.07381},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.07381}, 
}
